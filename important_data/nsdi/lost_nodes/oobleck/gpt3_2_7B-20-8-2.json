{"layers": [{"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 0, 5], "names": ["transformer.h.7.ln_1.weight", "transformer.h.7.ln_1.bias", "transformer.h.7.attn.c_attn.bias", "transformer.h.7.attn.c_attn.weight", "transformer.h.7.attn.c_proj.bias", "transformer.h.7.attn.c_proj.weight", "transformer.h.7.ln_2.weight", "transformer.h.7.ln_2.bias", "transformer.h.7.mlp.c_fc.bias", "transformer.h.7.mlp.c_fc.weight", "transformer.h.7.mlp.c_proj.bias", "transformer.h.7.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 0, 5], "names": ["transformer.h.8.ln_1.weight", "transformer.h.8.ln_1.bias", "transformer.h.8.attn.c_attn.bias", "transformer.h.8.attn.c_attn.weight", "transformer.h.8.attn.c_proj.bias", "transformer.h.8.attn.c_proj.weight", "transformer.h.8.ln_2.weight", "transformer.h.8.ln_2.bias", "transformer.h.8.mlp.c_fc.bias", "transformer.h.8.mlp.c_fc.weight", "transformer.h.8.mlp.c_proj.bias", "transformer.h.8.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 2, 7], "names": ["transformer.h.9.ln_1.weight", "transformer.h.9.ln_1.bias", "transformer.h.9.attn.c_attn.bias", "transformer.h.9.attn.c_attn.weight", "transformer.h.9.attn.c_proj.bias", "transformer.h.9.attn.c_proj.weight", "transformer.h.9.ln_2.weight", "transformer.h.9.ln_2.bias", "transformer.h.9.mlp.c_fc.bias", "transformer.h.9.mlp.c_fc.weight", "transformer.h.9.mlp.c_proj.bias", "transformer.h.9.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 2, 7], "names": ["transformer.h.10.ln_1.weight", "transformer.h.10.ln_1.bias", "transformer.h.10.attn.c_attn.bias", "transformer.h.10.attn.c_attn.weight", "transformer.h.10.attn.c_proj.bias", "transformer.h.10.attn.c_proj.weight", "transformer.h.10.ln_2.weight", "transformer.h.10.ln_2.bias", "transformer.h.10.mlp.c_fc.bias", "transformer.h.10.mlp.c_fc.weight", "transformer.h.10.mlp.c_proj.bias", "transformer.h.10.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 2, 7], "names": ["transformer.h.11.ln_1.weight", "transformer.h.11.ln_1.bias", "transformer.h.11.attn.c_attn.bias", "transformer.h.11.attn.c_attn.weight", "transformer.h.11.attn.c_proj.bias", "transformer.h.11.attn.c_proj.weight", "transformer.h.11.ln_2.weight", "transformer.h.11.ln_2.bias", "transformer.h.11.mlp.c_fc.bias", "transformer.h.11.mlp.c_fc.weight", "transformer.h.11.mlp.c_proj.bias", "transformer.h.11.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 2, 7], "names": ["transformer.h.12.ln_1.weight", "transformer.h.12.ln_1.bias", "transformer.h.12.attn.c_attn.bias", "transformer.h.12.attn.c_attn.weight", "transformer.h.12.attn.c_proj.bias", "transformer.h.12.attn.c_proj.weight", "transformer.h.12.ln_2.weight", "transformer.h.12.ln_2.bias", "transformer.h.12.mlp.c_fc.bias", "transformer.h.12.mlp.c_fc.weight", "transformer.h.12.mlp.c_proj.bias", "transformer.h.12.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [16, 2, 7], "names": ["transformer.h.13.ln_1.weight", "transformer.h.13.ln_1.bias", "transformer.h.13.attn.c_attn.bias", "transformer.h.13.attn.c_attn.weight", "transformer.h.13.attn.c_proj.bias", "transformer.h.13.attn.c_proj.weight", "transformer.h.13.ln_2.weight", "transformer.h.13.ln_2.bias", "transformer.h.13.mlp.c_fc.bias", "transformer.h.13.mlp.c_fc.weight", "transformer.h.13.mlp.c_proj.bias", "transformer.h.13.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [17, 8, 3], "names": ["transformer.h.18.ln_1.weight", "transformer.h.18.ln_1.bias", "transformer.h.18.attn.c_attn.bias", "transformer.h.18.attn.c_attn.weight", "transformer.h.18.attn.c_proj.bias", "transformer.h.18.attn.c_proj.weight", "transformer.h.18.ln_2.weight", "transformer.h.18.ln_2.bias", "transformer.h.18.mlp.c_fc.bias", "transformer.h.18.mlp.c_fc.weight", "transformer.h.18.mlp.c_proj.bias", "transformer.h.18.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [17, 8, 3], "names": ["transformer.h.19.ln_1.weight", "transformer.h.19.ln_1.bias", "transformer.h.19.attn.c_attn.bias", "transformer.h.19.attn.c_attn.weight", "transformer.h.19.attn.c_proj.bias", "transformer.h.19.attn.c_proj.weight", "transformer.h.19.ln_2.weight", "transformer.h.19.ln_2.bias", "transformer.h.19.mlp.c_fc.bias", "transformer.h.19.mlp.c_fc.weight", "transformer.h.19.mlp.c_proj.bias", "transformer.h.19.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [17, 8, 3], "names": ["transformer.h.20.ln_1.weight", "transformer.h.20.ln_1.bias", "transformer.h.20.attn.c_attn.bias", "transformer.h.20.attn.c_attn.weight", "transformer.h.20.attn.c_proj.bias", "transformer.h.20.attn.c_proj.weight", "transformer.h.20.ln_2.weight", "transformer.h.20.ln_2.bias", "transformer.h.20.mlp.c_fc.bias", "transformer.h.20.mlp.c_fc.weight", "transformer.h.20.mlp.c_proj.bias", "transformer.h.20.mlp.c_proj.weight"]}, {"sizes": [[2560], [2560], [7680], [2560, 7680], [2560], [2560, 2560], [2560], [2560], [10240], [2560, 10240], [2560], [10240, 2560]], "ranks": [18, 9, 4], "names": ["transformer.h.26.ln_1.weight", "transformer.h.26.ln_1.bias", "transformer.h.26.attn.c_attn.bias", "transformer.h.26.attn.c_attn.weight", "transformer.h.26.attn.c_proj.bias", "transformer.h.26.attn.c_proj.weight", "transformer.h.26.ln_2.weight", "transformer.h.26.ln_2.bias", "transformer.h.26.mlp.c_fc.bias", "transformer.h.26.mlp.c_fc.weight", "transformer.h.26.mlp.c_proj.bias", "transformer.h.26.mlp.c_proj.weight"]}], "world_size": 20}