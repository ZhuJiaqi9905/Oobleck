{"model": "gpt3_1_3B", "microbatch_size": 4, "world_size": 14, "pipelines": [{"layers": {"0": [0], "1": [0], "2": [0], "3": [0], "4": [0], "5": [0], "6": [0], "7": [1], "8": [1], "9": [1], "10": [1], "11": [1], "12": [1], "13": [1], "14": [1], "15": [1], "16": [1], "17": [2], "18": [2], "19": [2], "20": [2], "21": [2], "22": [2], "23": [2], "24": [2], "25": [2]}, "num_of_microbatches": 53, "num_layers_per_stage": [7, 10, 9]}, {"layers": {"0": [3], "1": [3], "2": [3], "3": [3], "4": [3], "5": [3], "6": [3], "7": [4], "8": [4], "9": [4], "10": [4], "11": [4], "12": [4], "13": [4], "14": [4], "15": [4], "16": [4], "17": [5], "18": [5], "19": [5], "20": [5], "21": [5], "22": [5], "23": [5], "24": [5], "25": [5]}, "num_of_microbatches": 53, "num_layers_per_stage": [7, 10, 9]}, {"layers": {"0": [6], "1": [6], "2": [6], "3": [6], "4": [6], "5": [6], "6": [7], "7": [8], "8": [8], "9": [8], "10": [8], "11": [8], "12": [8], "13": [8], "14": [8], "15": [8], "16": [8], "17": [9], "18": [9], "19": [9], "20": [9], "21": [9], "22": [9], "23": [9], "24": [9], "25": [9]}, "num_of_microbatches": 75, "num_layers_per_stage": [6, 1, 10, 9]}, {"layers": {"0": [10], "1": [10], "2": [10], "3": [10], "4": [10], "5": [10], "6": [11], "7": [12], "8": [12], "9": [12], "10": [12], "11": [12], "12": [12], "13": [12], "14": [12], "15": [12], "16": [12], "17": [13], "18": [13], "19": [13], "20": [13], "21": [13], "22": [13], "23": [13], "24": [13], "25": [13]}, "num_of_microbatches": 75, "num_layers_per_stage": [6, 1, 10, 9]}]}