{"model": "gpt3_1_3B", "microbatch_size": 4, "world_size": 12, "pipelines": [{"layers": {"0": [0], "1": [0], "2": [0], "3": [0], "4": [0], "5": [0], "6": [0], "7": [0], "8": [0], "9": [0], "10": [1], "11": [1], "12": [1], "13": [1], "14": [1], "15": [1], "16": [1], "17": [1], "18": [2], "19": [2], "20": [2], "21": [2], "22": [2], "23": [2], "24": [2], "25": [2]}, "num_of_microbatches": 64, "num_layers_per_stage": [10, 8, 8]}, {"layers": {"0": [3], "1": [3], "2": [3], "3": [3], "4": [3], "5": [3], "6": [3], "7": [3], "8": [3], "9": [3], "10": [4], "11": [4], "12": [4], "13": [4], "14": [4], "15": [4], "16": [4], "17": [4], "18": [5], "19": [5], "20": [5], "21": [5], "22": [5], "23": [5], "24": [5], "25": [5]}, "num_of_microbatches": 64, "num_layers_per_stage": [10, 8, 8]}, {"layers": {"0": [6], "1": [6], "2": [6], "3": [6], "4": [6], "5": [6], "6": [6], "7": [6], "8": [6], "9": [6], "10": [7], "11": [7], "12": [7], "13": [7], "14": [7], "15": [7], "16": [7], "17": [7], "18": [8], "19": [8], "20": [8], "21": [8], "22": [8], "23": [8], "24": [8], "25": [8]}, "num_of_microbatches": 64, "num_layers_per_stage": [10, 8, 8]}, {"layers": {"0": [9], "1": [9], "2": [9], "3": [9], "4": [9], "5": [9], "6": [9], "7": [9], "8": [9], "9": [9], "10": [10], "11": [10], "12": [10], "13": [10], "14": [10], "15": [10], "16": [10], "17": [10], "18": [11], "19": [11], "20": [11], "21": [11], "22": [11], "23": [11], "24": [11], "25": [11]}, "num_of_microbatches": 64, "num_layers_per_stage": [10, 8, 8]}]}